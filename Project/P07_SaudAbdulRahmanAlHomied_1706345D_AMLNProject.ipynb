{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "powerlifters = pd.read_csv(\"Data//powerlifting.csv\")\n",
    "\n",
    "# Replace blanks with NaN, fill all NaN values with \"0\"\n",
    "# Replace all negative values with \"1\"\n",
    "# Update dataframe with values\n",
    "# Replace 0's with \"NA\" and 1's with \"Fail\" and save to new CSV\n",
    "modifiedPowerlifters = powerlifters.replace(r'\\s+', np.nan, regex=True)\n",
    "# modifiedPowerlifters = powerlifters.fillna(0)\n",
    "for col in modifiedPowerlifters.columns[9:23]:\n",
    "    for i, row_value in modifiedPowerlifters[col].iteritems():\n",
    "        if row_value < 0:\n",
    "            modifiedPowerlifters.loc[i, col] = 0\n",
    "# modifiedPowerlifters = modifiedPowerlifters.replace(0, \"NA\")\n",
    "modifiedPowerlifters = modifiedPowerlifters.replace(\"M\", \"Male\")\n",
    "modifiedPowerlifters = modifiedPowerlifters.replace(\"F\", \"Female\")\n",
    "modifiedPowerlifters.to_csv('Data//modifiedPowerlifters.csv', index=False)\n",
    "\n",
    "# Override 'powerlifters' variable to read newly modified CSV file\n",
    "powerlifters = pd.read_csv(\"Data//modifiedPowerlifters.csv\")\n",
    "\n",
    "# Convert \"Date\" column to datetime for easier Data Exploration later\n",
    "powerlifters['Date'] = pd.to_datetime(powerlifters['Date'], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Description\n",
    "powerlifters.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Names\n",
    "print(powerlifters.columns)\n",
    "print(powerlifters.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 rows\n",
    "print(powerlifters.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Females and Males\n",
    "print(powerlifters.groupby('Sex').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of differnt types of equipment\n",
    "print(powerlifters.groupby('Equipment').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of different Age Classes\n",
    "print(powerlifters.groupby('AgeClass').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of different Weight Classes\n",
    "print(powerlifters.groupby('WeightClassKg').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Sex'].value_counts().plot(kind='bar', title='Male vs Female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Sex'].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['WeightClassKg'].value_counts().plot(kind='bar', figsize=(16,8), title='Count of Powerlifters in WeightClass(Kg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Age'].plot(kind='hist', bins=80, figsize=(16,8), title='age')\n",
    "plt.gca().grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Date'].dt.year.plot(kind='hist', bins=50, figsize=(16,8), title='Number of Powerlifters by Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['TotalKg'].hist(bins=200, figsize=(16,8))\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Best3SquatKg'].hist(bins=100, figsize=(16,8))\n",
    "plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Best3DeadliftKg'].hist(bins=100, figsize=(16,8))\n",
    "plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Best3BenchKg'].hist(bins=100, figsize=(16,8))\n",
    "plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Age'].value_counts().sort_index().plot.bar(figsize=(16,10), title='Powerlifters Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters[powerlifters['Sex'] == 'Male']['Age'].hist(bins=89, figsize=(16,10))\n",
    "powerlifters[powerlifters['Sex'] == 'Female']['Age'].hist(bins=89, figsize=(16,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifter_gender_age = pd.crosstab(powerlifters['Age'], powerlifters['Sex'])\n",
    "powerlifter_gender_age.plot.bar(stacked=True, figsize=(16,10), title='Powerlifters Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifter_gender_age.plot.bar(stacked=True, figsize=(16,10), title=\"Powerlifter's Age and Gender\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.savefig('graphs/genders-ages.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Equipment'].value_counts().plot(kind='bar', figsize=(16,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph based on the count of rows from a certain event, SBD is the highest\n",
    "powerlifters['Event'].value_counts().plot(kind='bar', figsize=(16,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each type of equipment\n",
    "# and assign it to a new variable with the values tolist()\n",
    "powerlifter_equipment = powerlifters['Equipment'].value_counts()\n",
    "powerlifter_size = powerlifter_equipment.values.tolist()\n",
    "powerlifter_labels = \"Wraps\", \"Multi-ply\", \"Single-ply\", \"Raw\"\n",
    "colours = ['#F38181','#EAFFD0','#95E1D3','#FCE38A','#BDE4F4','#9EF4E6']\n",
    "explode = (0.1,0,0,0)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.title('Powerlifters Equipment Type (Percentange)', fontsize=22)\n",
    "patches, texts, autotexts = plt.pie(powerlifter_size, explode=explode, labels=powerlifter_labels, colors=colours,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=150)\n",
    "\n",
    "for text,autotext in zip(texts,autotexts):\n",
    "    text.set_fontsize(14)\n",
    "    autotext.set_fontsize(14)\n",
    "\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters['Event'].value_counts().plot.pie(figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General plots\n",
    "sns.pairplot(powerlifters[['Age', 'Sex', 'BodyweightKg', 'Best3SquatKg', 'Best3BenchKg',\n",
    "                          'Best3DeadliftKg', 'TotalKg']], hue='Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression plots\n",
    "sns.pairplot(powerlifters[['Sex', 'BodyweightKg', 'Best3SquatKg', 'Best3BenchKg',\n",
    "                          'Best3DeadliftKg', 'TotalKg']], hue='Sex', kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_division = pd.crosstab(powerlifters['Date'].dt.year.astype(np.int), powerlifters['WeightClassKg'])\n",
    "years_division.plot(figsize=(16,10), title='# powerlifters per year and weight class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_division = pd.crosstab(powerlifters['Date'].dt.year.astype(np.int), powerlifters['Country'])\n",
    "years_division.plot(figsize=(16,10), title='# powerlifters per year and country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters.hist(figsize=(16,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(powerlifters['Best3DeadliftKg'], powerlifters['Best3BenchKg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_event = pd.crosstab(powerlifters['Country'], powerlifters['Event'])\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "mask = np.zeros_like(countries_event, dtype=np.bool)\n",
    "mask[countries_event == 0] = True\n",
    "\n",
    "sns.heatmap(countries_event, mask=mask, linewidth=.5, cmap=plt.cm.plasma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_eq = pd.crosstab(powerlifters['Country'], powerlifters['Equipment'])\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "mask = np.zeros_like(countries_eq, dtype=np.bool)\n",
    "mask[countries_eq == 0] = True\n",
    "\n",
    "sns.heatmap(countries_eq, mask=mask, linewidth=.5, cmap=plt.cm.plasma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerlifters = powerlifters.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the fields that we deem irrelevant\n",
    "# to the analysis we are making\n",
    "# Here we create a new variable to store the dataframe\n",
    "# with irrelevant features excluded to prevent it\n",
    "# from affecting the previous results\n",
    "\n",
    "fePowerlifters = powerlifters.copy()\n",
    "del fePowerlifters['Name']\n",
    "del fePowerlifters['Event']\n",
    "del fePowerlifters['AgeClass']\n",
    "del fePowerlifters['Division']\n",
    "del fePowerlifters['WeightClassKg']\n",
    "del fePowerlifters['Squat1Kg']\n",
    "del fePowerlifters['Squat2Kg']\n",
    "del fePowerlifters['Squat3Kg']\n",
    "del fePowerlifters['Squat4Kg']\n",
    "del fePowerlifters['Bench1Kg']\n",
    "del fePowerlifters['Bench2Kg']\n",
    "del fePowerlifters['Bench3Kg']\n",
    "del fePowerlifters['Bench4Kg']\n",
    "del fePowerlifters['Deadlift1Kg']\n",
    "del fePowerlifters['Deadlift2Kg']\n",
    "del fePowerlifters['Deadlift3Kg']\n",
    "del fePowerlifters['Deadlift4Kg']\n",
    "del fePowerlifters['Place']\n",
    "del fePowerlifters['Wilks']\n",
    "del fePowerlifters['McCulloch']\n",
    "del fePowerlifters['Glossbrenner']\n",
    "del fePowerlifters['IPFPoints']\n",
    "del fePowerlifters['Tested']\n",
    "del fePowerlifters['Country']\n",
    "del fePowerlifters['Federation']\n",
    "del fePowerlifters['Date']\n",
    "del fePowerlifters['MeetCountry']\n",
    "del fePowerlifters['MeetState']\n",
    "del fePowerlifters['MeetName']\n",
    "del fePowerlifters['Best3BenchKg']\n",
    "del fePowerlifters['Best3SquatKg']\n",
    "del fePowerlifters['TotalKg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fePowerlifters.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fePowerlifters.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical data (Sex) with one-hot encoded data\n",
    "features_pl = pd.get_dummies(fePowerlifters, columns=['Sex', 'Equipment'])\n",
    "\n",
    "# # Create variable for Best3SquatKg Analysis\n",
    "# # 'sq' = Squats\n",
    "# features_sq = pd.get_dummies(fePowerlifters, columns=['Sex', 'Equipment'])\n",
    "# del features_sq['Best3BenchKg']\n",
    "# del features_sq['Best3DeadliftKg']\n",
    "# del features_sq['TotalKg']\n",
    "\n",
    "# # Remove output value to be used as 'y' for training\n",
    "# del features_sq['Best3SquatKg']\n",
    "\n",
    "# # Create variable for Best3BenchKg Analysis\n",
    "# # 'bh' = Bench\n",
    "# features_bh = pd.get_dummies(fePowerlifters, columns=['Sex', 'Equipment'])\n",
    "# del features_bh['Best3SquatKg']\n",
    "# del features_bh['Best3DeadliftKg']\n",
    "# del features_bh['TotalKg']\n",
    "\n",
    "# # Remove output value to be used as 'y' for training\n",
    "# del features_bh['Best3BenchKg']\n",
    "\n",
    "# Create variable for Best3DeadliftKg Analysis\n",
    "# 'dl' = Deadlift\n",
    "features_dl = pd.get_dummies(fePowerlifters, columns=['Sex', 'Equipment'])\n",
    "\n",
    "# Remove output value to be used as 'y' for training\n",
    "del features_dl['Best3DeadliftKg']\n",
    "\n",
    "# # Create variable for TotalKg Analysis\n",
    "# # 'total' = TotalKg\n",
    "# features_total = pd.get_dummies(fePowerlifters, columns=['Sex', 'Equipment'])\n",
    "# del features_total['Best3BenchKg']\n",
    "# del features_total['Best3SquatKg']\n",
    "# del features_total['Best3DeadliftKg']\n",
    "\n",
    "# # Remove output value to be used as 'y' for training\n",
    "# del features_total['TotalKg']\n",
    "\n",
    "# Create separate variable identical to 'features_pl' for use later\n",
    "features_impt = pd.get_dummies(fePowerlifters, columns=['Sex', 'Equipment'])\n",
    "\n",
    "# Create the X and y arrays, X being the input data and y being the output data,\n",
    "# the value we are predicting\n",
    "# Arrays for training 'deadlift'\n",
    "X = features_dl.values\n",
    "y = features_pl['Best3DeadliftKg'].values\n",
    "\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Checking Algorithms\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = []\n",
    "models.append(('Linear Regression', LinearRegression()))\n",
    "models.append(('SGDRegressor', SGDRegressor(max_iter=1000, tol=1e-3)))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('ElasticNet', ElasticNet()))\n",
    "models.append(('KNeighborsRegressor', KNeighborsRegressor()))\n",
    "models.append(('DecisionTreeRegressor', DecisionTreeRegressor()))\n",
    "models.append(('GradientBoostingRegressor', ensemble.GradientBoostingRegressor()))\n",
    "models.append(('SupportVectorMachines', SVR(gamma='auto')))\n",
    "models.append(('RandomForestRegressor', ensemble.RandomForestRegressor(max_depth=2, random_state=seed, n_estimators=100)))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Implement Grid Search to determine the best paramters for Algorithm (GradientBoostingRegressor)\n",
    "# Parameters we want to try\n",
    "# Run only if needed\n",
    "\n",
    "gbr = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000, 3000],\n",
    "    'max_depth': [2, 4, 6],\n",
    "    'min_samples_leaf': [3, 5, 9, 17],\n",
    "    'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "    'max_features': [1.0, 0.3, 0.1],\n",
    "    'loss': ['ls', 'lad', 'huber']\n",
    "}\n",
    "\n",
    "# Define the grid search we want to run. Run it with four cpus in parallel\n",
    "gs_cv = GridSearchCV(gbr, param_grid, n_jobs=6, verbose=100)\n",
    "\n",
    "# Run the grid search - on only the training data!\n",
    "gs_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the parameters that gave us the best result!\n",
    "print(gs_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "# Testing out new hyper-parameters\n",
    "# From results of GridSearch\n",
    "# After running GridSearch, BestParameters: \n",
    "# {'learning_rate': 0.01, 'loss': 'ls', 'max_depth': 4, 'max_features': 0.3, 'min_samples_leaf': 3, 'n_estimators': 1000}\n",
    "\n",
    "# The combination that worked best\n",
    "gbr = ensemble.GradientBoostingRegressor(\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=4,\n",
    "                min_samples_leaf=3,\n",
    "                max_features=0.3,\n",
    "                loss='ls',\n",
    "                random_state=seed\n",
    ")\n",
    " \n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file so we can use it in other programs\n",
    "joblib.dump(gbr, \"models//gs_trained_deadlift_regressor_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "# With Default hyper-parameters without GridSearch\n",
    "gbr = ensemble.GradientBoostingRegressor(\n",
    "                n_estimators=1000,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                min_samples_leaf=9,\n",
    "                max_features=0.1,\n",
    "                loss='huber',\n",
    "                random_state=seed\n",
    ")\n",
    " \n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file so we can use it in other programs\n",
    "joblib.dump(gbr, \"models//trained_deadlift_regressor_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the feature labels from our data set\n",
    "feature_labels = features_impt.columns\n",
    "\n",
    "# Load the trained model created previously\n",
    "model = joblib.load('models//trained_deadlift_regressor_model.pkl')\n",
    "model_gs = joblib.load('models//gs_trained_deadlift_regressor_model.pkl')\n",
    "\n",
    "# Create a numpy array based on the model's feature importances\n",
    "importance = model.feature_importances_\n",
    "importance_gs = model_gs.feature_importances_\n",
    "\n",
    "# Sort the feature labels based on the feature importance rankings from the model\n",
    "feature_indexes_by_importance = importance.argsort()\n",
    "feature_indexes_by_importance_gs = importance_gs.argsort()\n",
    "\n",
    "# Print each feature label, from most important to least important (reverse order)\n",
    "print(\"Most to Least Important Features without GridSearch Optimization\")\n",
    "print(\"\")\n",
    "for index in feature_indexes_by_importance:\n",
    "    print(\"{} - {:2f}%\".format(feature_labels[index], (importance[index] * 100.0)))\n",
    "print(\"\")\n",
    "    \n",
    "print(\"Most to Least Important Features with GridSearch Optimization\")\n",
    "print(\"\")\n",
    "for index in feature_indexes_by_importance_gs:\n",
    "    print(\"{} - {:2f}%\".format(feature_labels[index], (importance_gs[index] * 100.0)))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Total Weight lifted, we need to provide the features in the exact same\n",
    "# arrangement as our training data set\n",
    "weight_lifted = [\n",
    "    # Lifter features\n",
    "    21, # Age\n",
    "    80.0, # BodyweightKg\n",
    "    \n",
    "    # Sex: Choose only one\n",
    "    0, # Female\n",
    "    1, # Male\n",
    "    \n",
    "    # Equipment: Choose only one\n",
    "    0, # Multi-ply\n",
    "    1, # Raw\n",
    "    0, # Single-ply\n",
    "    0, # Wraps\n",
    "]\n",
    "\n",
    "lifts_to_value = [\n",
    "    weight_lifted\n",
    "]\n",
    "\n",
    "predicted_lift_values = model.predict(lifts_to_value)\n",
    "predicted_lift_values_gs = model_gs.predict(lifts_to_value)\n",
    "\n",
    "predicted_value = predicted_lift_values[0]\n",
    "gs_predicted_value = predicted_lift_values_gs[0]\n",
    "\n",
    "print(\"Before GridSearch: This person has an estimated deadlift of {:,.2f}kg\".format(predicted_value))\n",
    "print(\"After GridSearch: This person has an estimated deadlift of {:,.2f}kg\".format(gs_predicted_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Error rate before implementing GridSearch 'best-parameters'\n",
    "print(\"Before GridSearch:\")\n",
    "# Find the error rate on the training set\n",
    "mse = mean_absolute_error(y_train, model.predict(X_train))\n",
    "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
    "\n",
    "# Find the error rate on the test set\n",
    "mse = mean_absolute_error(y_test, model.predict(X_test))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mse)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Error rate after implementing GridSearch 'best-parameters'\n",
    "print(\"After GridSearch:\")\n",
    "# Find the error rate on the training set\n",
    "mse = mean_absolute_error(y_train, model_gs.predict(X_train))\n",
    "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
    "\n",
    "# Find the error rate on the test set\n",
    "mse = mean_absolute_error(y_test, model_gs.predict(X_test))\n",
    "print(\"Test Set Mean Absolute Error: %.4f\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
